{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krisztina/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFlowNetworkDiscrete(nn.Module):\n",
    "    \"\"\"\n",
    "    Bayesian Flow Network for discrete data.\n",
    "    \n",
    "    Parameters:\n",
    "    D (int): dimensionality of data\n",
    "    K (int): number of classes\n",
    "    network: network used for predictions for p_output\n",
    "    beta1 (float): initial beta parameter\n",
    "    \"\"\"\n",
    "    def __init__(self, D=2, K=2, model=None, beta1=3.0):\n",
    "        super(BayesianFlowNetworkDiscrete, self).__init__()\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.beta1 = beta1\n",
    "\n",
    "        output_classes=K if K>2 else 1\n",
    "\n",
    "        if model == None:\n",
    "            hidden_dim = 128\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(D * K + 1, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, D * output_classes)\n",
    "                )\n",
    "        else:\n",
    "            self.model = model\n",
    "\n",
    "\n",
    "    def forward(self, theta, t):\n",
    "            \"\"\"\n",
    "            \n",
    "            \"\"\"\n",
    "            theta = (theta * 2) - 1 # rescale to [-1, 1] to have distribution centered around 0\n",
    "            theta = theta.view(theta.shape[0], -1) # (B, D*K)\n",
    "            input_ = torch.cat((theta, t.unsqueeze(-1)), dim=-1) # (B, D*K + 1)\n",
    "            output = self.model(input_) # (B, D*K)\n",
    "            output =  output.view(output.shape[0], self.D, -1) # (B, D, K)\n",
    "            return output\n",
    "\n",
    "\n",
    "    def discrete_output_distribution(self, theta:torch.Tensor, t:torch.Tensor)->torch.Tensor:\n",
    "            \"\"\"\n",
    "            Parameters:\n",
    "            theta (torch.Tensor): Input tensor of shape (B, D, K).\n",
    "            t (torch.Tensor): Time tensor of shape (B,).\n",
    "            \n",
    "            Returns:\n",
    "            p_out (torch.Tensor): Output probability tensor. \n",
    "                                  If K=2, tensor shape is (B, D, 2). \n",
    "                                  If K>2, tensor shape is (B, D, K).\n",
    "            \"\"\"\n",
    "            net_output = self.forward(theta, t) # (B, D, K)\n",
    "\n",
    "            if self.K == 2:\n",
    "                po_1 = torch.sigmoid(net_output) # (B, D, K)\n",
    "                po_2 = 1 - po_1\n",
    "                p_out = torch.cat((po_1, po_2), dim=-1) # (B, D, 2)\n",
    "\n",
    "            else:\n",
    "                p_out = torch.softmax(net_output, dim=-1) # (B, D, K)\n",
    "\n",
    "            return p_out\n",
    "            \n",
    "\n",
    "    def training_continuous_loss(self, x:torch.Tensor):\n",
    "            B, D = x.shape\n",
    "\n",
    "            # Sample t~U(0, 1)\n",
    "            t = torch.rand((B,), device=x.device, dtype=torch.float32) # (B,)\n",
    "\n",
    "            # Calculate beta\n",
    "            beta = self.beta1 * (t**2) # (B,)\n",
    "\n",
    "            # Sample y from p_sender N(beta*(K * e_x - 1), beta * K * I)\n",
    "            e_x = F.one_hot(x, num_classes=self.K) # (B, D, K)\n",
    "            mean = beta.unsqueeze(-1).unsqueeze(-1) * (self.K * e_x.float() - 1) # (B, D, K); beta[:, None, None] for broadcasting\n",
    "            std = (beta.unsqueeze(-1).unsqueeze(-1) * self.K).sqrt() # (B, D, K)\n",
    "            # epsilon = torch.rand_like(mean) # (B, D, K)\n",
    "            # y = mean + std*epsilon # (B, D, K)\n",
    "            y = torch.distributions.Normal(mean, std).sample() # (B, D, K)\n",
    "\n",
    "            # Update theta\n",
    "            theta = torch.softmax(y, dim=-1) # (B, D, K)\n",
    "\n",
    "            # Calculate p_output\n",
    "            p_output = self.discrete_output_distribution(theta, t) # (B, D, K)\n",
    "\n",
    "            # Calculate coninuous Loss\n",
    "            e_hat = p_output\n",
    "            Loss_infty = self.K * self.beta1 * t[:, None, None] * ((e_x - e_hat)**2) # (B, D, K)\n",
    "\n",
    "            return Loss_infty.mean()\n",
    "        \n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def sample(self, batch_size:int, n_steps:int, device='cpu'):\n",
    "            self.eval()\n",
    "\n",
    "            # prior theta\n",
    "            theta = torch.ones(size=(batch_size, self.D, self.K), device=device) / self.K # (batch_size, D, K)\n",
    "\n",
    "            # generation loop\n",
    "            for i in range(1, n_steps):\n",
    "                # Calculate t\n",
    "                t = (i - 1)/n_steps # scalar\n",
    "                t = t * torch.ones((theta.shape[0],), device=theta.device, dtype=theta.dtype) # (batch_size,)\n",
    "                \n",
    "                # Calculate k\n",
    "                k_probs = self.discrete_output_distribution(theta, t)  # (B, D, K)\n",
    "                k = torch.distributions.Categorical(probs=k_probs).sample() # (B, D) # should we do Multinomial??\n",
    "\n",
    "                # Calculate alpha\n",
    "                alpha = self.beta1 * ((2*i - 1) / n_steps**2) # scalar\n",
    "\n",
    "                # Sample y from N(alpha*(K * e_k - 1), alpha * K * I)\n",
    "                e_k = F.one_hot(k, num_classes=self.K).float()  # (B, D, K)\n",
    "                mean = alpha * (self.K * e_k -1) # (B, D, K)\n",
    "                var = (alpha * self.K)\n",
    "                std = torch.full_like(mean, fill_value=var, device=device).sqrt() # (B, D, K)\n",
    "                # epsilon = torch.randn_like(mean)\n",
    "                # y = mean + std * epsilon # (B, D, K)\n",
    "                y = torch.distributions.Normal(mean, std).sample() # (B, D, K)\n",
    "\n",
    "                # Update theta\n",
    "                theta_prime = torch.exp(y) * theta # (B, D, K)\n",
    "                sum_theta_prime = theta_prime.sum(-1, keepdim=True) # (B, D, 1)\n",
    "                theta = theta_prime / sum_theta_prime # (B, D, K)\n",
    "            \n",
    "            k_probs = self.discrete_output_distribution(theta, torch.ones_like(t))  # (B, D, K)\n",
    "            k_output_sample = torch.distributions.Categorical(probs=k_probs).sample()\n",
    "            \n",
    "            return k_output_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# network should learn\n",
    "# when x0=0, x1=1\n",
    "# when x0=1, x1=0\n",
    "\n",
    "def get_datapoint(batch=128, device=\"cpu\"):\n",
    "  x0 = torch.randint(low=0, high=2, size=(batch,), dtype=torch.bool, device=device) # (batch,)\n",
    "  x1 = ~x0\n",
    "\n",
    "  X = torch.stack([x0, x1], dim=0) # (2, batch)\n",
    "  return X.long().transpose(0,1) # (batch, 2)\n",
    "\n",
    "X = get_datapoint() # (B, D=2) K = 2 classes\n",
    "\n",
    "plt.title(\"Dataset\")\n",
    "plt.scatter(X[0,:], X[1,:])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      4\u001b[0m bfn \u001b[38;5;241m=\u001b[39m BayesianFlowNetworksDiscrete()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mbfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m optim \u001b[38;5;241m=\u001b[39m AdamW(bfn\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-2\u001b[39m)\n\u001b[1;32m      9\u001b[0m n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/torch/nn/modules/module.py:911\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    895\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    896\u001b[0m \n\u001b[1;32m    897\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/MLMI/Advanced_ML/BayesianFLowNetworks/.conda/lib/python3.11/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "bfn = BayesianFlowNetworksDiscrete()\n",
    "bfn.cuda()\n",
    "\n",
    "optim = AdamW(bfn.parameters(), lr=1e-2)\n",
    "\n",
    "n=1000\n",
    "losses=[]\n",
    "for i in tqdm(range(n)):\n",
    "  optim.zero_grad()\n",
    "\n",
    "  X = get_datapoint(device=\"cpu\")\n",
    "  loss = bfn.process(X)\n",
    "  loss.backward()\n",
    "\n",
    "  optim.step()\n",
    "\n",
    "  losses.append(loss.item())\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
