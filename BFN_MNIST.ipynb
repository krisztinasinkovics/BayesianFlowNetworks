{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch_ema\n",
    "\n",
    "# import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "\n",
    "# import numpy as np\n",
    "# import random\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm.auto import tqdm\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# from bfn.bfn_discrete import VanillaBFNDiscrete\n",
    "# from models.unet_improved import UNetModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('/home/krisztina/Documents/MLMI/Advanced_ML/BayesianFlowNetworks/')\n",
    "from trainer import DiscreteBFNTrainer\n",
    "trainer = DiscreteBFNTrainer(wandb_project_name=None, device='cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input x: torch.Size([32, 1, 28, 28])\n",
    "# falttened x: torch.Size([32, 784])\n",
    "# x.dtype: torch.int64\n",
    "# x: torch.Size([32, 784])\n",
    "# e_x: torch.Size([32, 784, 2])\n",
    "# beta: torch.Size([32, 784, 1])\n",
    "# y shape: torch.Size([32, 784, 2])\n",
    "# theta shape: torch.Size([32, 784, 2])\n",
    "# t shape: torch.Size([32, 784])\n",
    "# FourierIIA img.shape torch.Size([32, 784, 1])\n",
    "# FourierIIA img.shape torch.Size([32, 28, 28, 1])\n",
    "# FourierIIA t.shape torch.Size([32, 784, 1])\n",
    "# flat_img.shape torch.Size([32, 784, 1])\n",
    "# flat_t.shape torch.Size([32, 784, 1])\n",
    "# t_feats.shape torch.Size([32, 784, 1])\n",
    "# all_feat_list[0].shape torch.Size([32, 784, 1])\n",
    "# all_feat_list[1].shape torch.Size([32, 784, 1])\n",
    "#  model output shape: torch.Size([32, 784, 1])\n",
    "# p_output or e_hat shape: torch.Size([32, 784, 2])\n",
    "# e_x shape: torch.Size([32, 784, 2])\n",
    "# t shape: torch.Size([32, 784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# input_shape = [28, 28]\n",
    "# input_channels = 1\n",
    "# img = torch.randn((32, 784, 1))\n",
    "# img = img.reshape(-1, *input_shape, input_channels)\n",
    "# print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.utils import get_image_grid_from_tensor\n",
    "model = trainer.bfn_model\n",
    "model.eval()\n",
    "\n",
    "# Generate samples and priors\n",
    "samples, priors = model.sample_generation_for_discretised_data(n_steps=5)\n",
    "samples = samples.to(torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krisztina/Documents/MLMI/Advanced_ML/BayesianFlowNetworks/.conda/lib/python3.11/site-packages/torch/cuda/__init__.py:141: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "DATAPATH = \"./data/\"\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAVE_MODEL = True\n",
    "MODELS_PATH = \"./models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(dataloader: torch.utils.data.DataLoader) -> tuple[torch.Tensor, int]:\n",
    "    \"\"\"\n",
    "    Returns a random sample from a data loader\n",
    "\n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): data loader storing the images.\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, int]: (image, label)\n",
    "    \"\"\"\n",
    "    for sample in dataloader:\n",
    "        return sample[0], sample[1][0].numpy()\n",
    "    raise IndexError(\"Could not sample an empty data loader.\")\n",
    "    \n",
    "def show_samples(dataloader: torch.utils.data.DataLoader, n: int, title: str=None) -> None:\n",
    "    \"\"\"\n",
    "    Displays some random samples from a data loader.\n",
    "\n",
    "    Args:\n",
    "        dataloader (torch.utils.data.DataLoader): data loader storing the images.\n",
    "        n (int): number of samples to display.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, n, figsize=(3*n, 3))\n",
    "    for i in range(n):\n",
    "        img, label = get_sample(dataloader)\n",
    "        ax[i].imshow(img[0][0], cmap='Greys_r', interpolation='nearest')\n",
    "        ax[i].set_title(label)\n",
    "        ax[i].axis(\"off\")\n",
    "    title = title if title else f\"{n} random samples\"\n",
    "    fig.suptitle(title, position=(0.5, 1.1))\n",
    "    \n",
    "def moving_average(data: list[float], window_size: int=20) -> list[float]:\n",
    "    \"\"\"\n",
    "    Computes the moving average of a list of values.\n",
    "\n",
    "    Args:\n",
    "        data (list[float]): list of values.\n",
    "        window_size (int, optional): length of the window over which the values will be averaged out. Defaults to 20.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: list of averaged values.\n",
    "    \"\"\"\n",
    "    moving_avg = []\n",
    "    for i in range(len(data) - window_size + 1):\n",
    "        window = data[i : i + window_size]\n",
    "        avg = sum(window) / window_size\n",
    "        moving_avg.append(avg)\n",
    "    return moving_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:05<00:00, 1698644.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 28263111.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1648877/1648877 [00:00<00:00, 1653096.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6955286.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)) # normalize pixel values to [-1, 1]\n",
    "])\n",
    "\n",
    "#download and load the MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root=DATAPATH, train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root=DATAPATH, train=False, download=True, transform=transform)\n",
    "\n",
    "#create data loaders\n",
    "batch_size=64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicallyBinarizedMNIST(torchvision.datasets.MNIST):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None, download=False):\n",
    "        super(DynamicallyBinarizedMNIST, self).__init__(root, train=train, transform=transform,\n",
    "                                                        target_transform=target_transform, download=download)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "def collate_dynamic_binarize(batch: list[tuple[torch.Tensor, int]]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Collate function that samples a binarization probability for each batch.\n",
    "\n",
    "    Args:\n",
    "        batch (list[tuple[torch.Tensor, int]]): list of samples to collate.\n",
    "\n",
    "    Returns:\n",
    "        tuple[torch.Tensor, torch.Tensor]: resulting batch.\n",
    "    \"\"\"\n",
    "    images, targets = zip(*batch)\n",
    "    binarization_probs = torch.rand(len(images))\n",
    "    binarized_images = []\n",
    "    for img, prob in zip(images, binarization_probs):\n",
    "        binarized_img = (img > prob).float()\n",
    "        binarized_images.append(binarized_img)\n",
    "    return torch.stack(binarized_images)[:, None, ...].to(torch.int64), torch.tensor(targets)\n",
    "\n",
    "# Create the dynamically binarized MNIST dataset\n",
    "train_dataset = DynamicallyBinarizedMNIST(root=DATAPATH, train=True, download=True) # transform=transform\n",
    "test_dataset = DynamicallyBinarizedMNIST(root=DATAPATH, train=False, download=True) # transform=transform\n",
    "\n",
    "# Create data loaders with the collate function\n",
    "batch_size = 512\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_dynamic_binarize)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_dynamic_binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in the training dataset: 118\n",
      "Number of data points in the training dataset: 20\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAAEtCAYAAABJdaqWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApi0lEQVR4nO3deZAV5bk/8OfAyAzOCKgMqwiCXGVw4YpiFAUElRAUjbK4RXBDo8alcLmJvwhyFSPGJaVB0biLN1EwiDuS4Bo1VHmjCCIakERwYRFEBYShf39Yc66HGWBAmjMDn08VVcw7fbqf091vnzPfervfTJIkSQAAAADAFlYn3wUAAAAAsG0SPAEAAACQCsETAAAAAKkQPAEAAACQCsETAAAAAKkQPAEAAACQCsETAAAAAKkQPAEAAACQCsETAAAAAKkQPAGw3RoyZEi0adMm32XUej169IgePXps1W2uWbMmrrjiimjVqlXUqVMnjj/++K26/Zrk/vvvj0wmEx999NEmv/bFF1+MTCYTL7744hava3ONGDEiMplMvssAALYQwRMAqav4w7jiX0FBQbRs2TKGDBkS8+fPz3d51EL33ntv3HjjjdG/f/944IEH4tJLL813SRs0atSomDhxYr7L2OaNGTMm7r///nyXERERCxYsiBEjRsQ//vGPfJcCAHlVkO8CANh+jBw5MvbYY49YuXJlvPHGG3H//ffHq6++Gu+++24UFRXluzxqkb/+9a/RsmXLuOWWW/JdSrWMGjUq+vfvn8rIrJ/97Gdx0kknRWFh4Sa/tlu3brFixYqoV6/eFq8rH8aMGRONGzeOIUOG5LuUWLBgQVxzzTXRpk2b6NSpU77LAYC8ETwBsNX06dMnDjzwwIiIOPvss6Nx48Zxww03xKRJk2LgwIF5ro7a5PPPP49GjRptdLk1a9bE2rVra1Ww8vXXX0dxcXG1l69bt27UrVt3s7ZVp04doS8AkCq32gGQN4cffnhERPzzn//Mtn377bdx9dVXR+fOnaNhw4ZRXFwchx9+eEydOjXntR999FFkMpn47W9/G3fddVe0a9cuCgsL46CDDopp06ZV2tbEiRNjn332iaKiothnn33iz3/+c5U1ff311zFs2LBo1apVFBYWxl577RW//e1vI0mSnOUymUxceOGF8dhjj0VZWVnUr18/DjnkkJg+fXpERIwdOzb23HPPKCoqih49elTr+TvLly+PSy65JNq0aROFhYXRpEmTOOqoo+Ktt97KLvPKK6/EgAEDYvfdd4/CwsJo1apVXHrppbFixYqcdQ0ZMiRKSkriX//6VxxzzDFRUlISLVu2jN///vcRETF9+vTo2bNnFBcXR+vWreORRx7JeX3F7ZEvv/xynHvuubHrrrtGgwYN4vTTT48vvvhio+9l1apVMXz48Nhzzz2zdV5xxRWxatWqnOVeeOGFOOyww6JRo0ZRUlISe+21V/zqV79a73orjvvUqVNjxowZ2ds3X3zxxZxz4tZbb82eEzNnzoyI70ZJHX744VFcXByNGjWK4447Lt57772c9Vc8X2j27Nlx2mmnRcOGDaO0tDR+/etfR5Ik8e9//zuOO+64aNCgQTRr1ixuuummje6LTCYTX3/9dTzwwAPZeitG5FRsb+bMmXHKKafEzjvvHIcddlhERLzzzjsxZMiQaNu2bRQVFUWzZs3izDPPjMWLF1d5rL5/jrVp0yaOOeaYePXVV6NLly5RVFQUbdu2jQcffDDntVU946lHjx6xzz77xMyZM+OII46IHXfcMVq2bBmjR4+u9N7mzZsX/fr1i+Li4mjSpElceuml8fzzz1f7uVGvvvpqHHTQQVFUVBTt2rWLsWPHVrncfffdFz179owmTZpEYWFhlJWVxR133JGzTJs2bWLGjBnx0ksvZfdzxbPHlixZEpdddlnsu+++UVJSEg0aNIg+ffrE22+/XWlbt912W3Ts2DF23HHH2HnnnePAAw+s1D/mz58fZ555ZjRt2jQKCwujY8eOce+99+bs14MOOigiIs4444xsPTXlNkAA2JqMeAIgbyr+UN55552zbV9++WX84Q9/iJNPPjnOOeecWL58edxzzz3Ru3fv+Pvf/17plpVHHnkkli9fHueee25kMpkYPXp0nHDCCTFnzpzYYYcdIiJi8uTJceKJJ0ZZWVlcf/31sXjx4jjjjDNit912y1lXkiTRr1+/mDp1apx11lnRqVOneP755+Pyyy+P+fPnV7qt65VXXolJkybFBRdcEBER119/fRxzzDFxxRVXxJgxY+L888+PL774IkaPHh1nnnlm/PWvf93g/jjvvPNi/PjxceGFF0ZZWVksXrw4Xn311XjvvffigAMOiIiIxx57LL755pv4+c9/Hrvuumv8/e9/j9tuuy0+/vjjeOyxx3LWV15eHn369Ilu3brF6NGjY9y4cXHhhRdGcXFxXHXVVXHqqafGCSecEHfeeWecfvrpccghh8Qee+yRs44LL7wwGjVqFCNGjIj3338/7rjjjpg3b142sKjK2rVro1+/fvHqq6/G0KFDo0OHDjF9+vS45ZZbYvbs2dlnHc2YMSOOOeaY2G+//WLkyJFRWFgYH374Ybz22mvr3UelpaXx0EMPxXXXXRdfffVVXH/99RER0aFDh2z4dt9998XKlStj6NChUVhYGLvssktMmTIl+vTpE23bto0RI0bEihUr4rbbbouuXbvGW2+9Vekh84MGDYoOHTrEb37zm3j66afj2muvjV122SXGjh0bPXv2jBtuuCHGjRsXl112WRx00EHRrVu39db80EMPxdlnnx1dunSJoUOHRkREu3btcpYZMGBAtG/fPkaNGpUNOV944YWYM2dOnHHGGdGsWbOYMWNG3HXXXTFjxox44403NvoA7g8//DD69+8fZ511VgwePDjuvffeGDJkSHTu3Dk6duy4wdd+8cUX8eMf/zhOOOGEGDhwYIwfPz6uvPLK2HfffaNPnz4R8V1I27Nnz/jkk0/i4osvjmbNmsUjjzxSKSRen+nTp8fRRx8dpaWlMWLEiFizZk0MHz48mjZtWmnZO+64Izp27Bj9+vWLgoKCePLJJ+P888+PtWvXZvvfrbfeGr/4xS+ipKQkrrrqqoiI7LrmzJkTEydOjAEDBsQee+wRn332WYwdOza6d+8eM2fOjBYtWkRExN133x0XXXRR9O/fPy6++OJYuXJlvPPOO/Hmm2/GKaecEhERn332WfzoRz/Khs+lpaXx7LPPxllnnRVffvllXHLJJdGhQ4cYOXJkXH311TF06NBsyH7ooYdWa98AwDYlAYCU3XfffUlEJFOmTEkWLlyY/Pvf/07Gjx+flJaWJoWFhcm///3v7LJr1qxJVq1alfP6L774ImnatGly5plnZtvmzp2bRESy6667JkuWLMm2P/HEE0lEJE8++WS2rVOnTknz5s2TpUuXZtsmT56cRETSunXrbNvEiROTiEiuvfbanO33798/yWQyyYcffphti4iksLAwmTt3brZt7NixSUQkzZo1S7788sts+y9/+cskInKWrUrDhg2TCy64YIPLfPPNN5Xarr/++iSTySTz5s3Ltg0ePDiJiGTUqFHZti+++CKpX79+kslkkj/+8Y/Z9lmzZiURkQwfPjzbVnHMOnfunHz77bfZ9tGjRycRkTzxxBPZtu7duyfdu3fP/vzQQw8lderUSV555ZWcOu+8884kIpLXXnstSZIkueWWW5KISBYuXLjB91yV7t27Jx07dsxpqzgnGjRokHz++ec5v+vUqVPSpEmTZPHixdm2t99+O6lTp05y+umnZ9uGDx+eREQydOjQbNuaNWuS3XbbLclkMslvfvObbHvF/hw8ePBG6y0uLq5yuYrtnXzyyZV+V9Wx/p//+Z8kIpKXX34521ZxrL5/frVu3brScp9//nlSWFiYDBs2LNs2derUJCKSqVOnZtu6d++eRETy4IMPZttWrVqVNGvWLDnxxBOzbTfddFMSEcnEiROzbStWrEj23nvvSuusyvHHH58UFRXlnLczZ85M6tatm6z7FbWqfdG7d++kbdu2OW0dO3bMORcrrFy5MikvL89pmzt3blJYWJiMHDky23bcccdVOq/WddZZZyXNmzdPFi1alNN+0kknJQ0bNszWOm3atCQikvvuu2+D6wOAbZ1b7QDYao488sgoLS2NVq1aRf/+/aO4uDgmTZqUM/Kobt262efxrF27NpYsWRJr1qyJAw88MOeWswqDBg3KGTFVMbJgzpw5ERHxySefxD/+8Y8YPHhwNGzYMLvcUUcdFWVlZTnreuaZZ6Ju3bpx0UUX5bQPGzYskiSJZ599Nqe9V69eOSNlDj744IiIOPHEE2OnnXaq1F5R0/o0atQo3nzzzViwYMF6l6lfv372/19//XUsWrQoDj300EiSJP73f/+30vJnn312zvr32muvKC4uznmm1l577RWNGjWqsr6hQ4dmR45FRPz85z+PgoKCeOaZZ9Zb42OPPRYdOnSIvffeOxYtWpT917Nnz4iI7IiYimc0PfHEE7F27dr1rm9TnXjiiVFaWpr9ueIcGDJkSOyyyy7Z9v322y+OOuqoKt/L9/db3bp148ADD4wkSeKss87Ktlfsz40d1+o477zzKrV9/1ivXLkyFi1aFD/60Y8iIqrsC+sqKyvL9oeI70aLVbfekpKSOO2007I/16tXL7p06ZLz2ueeey5atmwZ/fr1y7YVFRXFOeecs9H1l5eXx/PPPx/HH3987L777tn2Dh06RO/evSst//19sWzZsli0aFF079495syZE8uWLdvo9goLC6NOnTrZbS9evDh7a+f392WjRo3i448/rvJ23YjvRkVOmDAhjj322EiSJOf87t27dyxbtqxaxwYAtieCJwC2mt///vfxwgsvxPjx4+MnP/lJLFq0qMqZuB544IHYb7/9oqioKHbdddcoLS2Np59+uso/ML//R2vE/922V/Econnz5kVERPv27Su9dq+99sr5ed68edGiRYuc0Cjiuz+Gv7+u9W27Ithq1apVle0bezbS6NGj4913341WrVpFly5dYsSIEZVCgn/961/ZAKWkpCRKS0uje/fuERGV9k9RUVFOAFNRy2677VbpNq2GDRtWWd+6+62kpCSaN2++wWdWffDBBzFjxowoLS3N+fcf//EfEfHdg8EjvgsNu3btGmeffXY0bdo0TjrppHj00Ud/cAi17u2CFcdt3eMd8d2xXbRoUXz99dc57VUd26KiomjcuHGl9uo882pTa4747rlEF198cTRt2jTq168fpaWl2eWqE7as+x4ivusf1am3qnNk3dfOmzcv2rVrV2m5Pffcc6PrX7hwYaxYsaJa/TIi4rXXXosjjzwy+3yu0tLS7LPAqrMv1q5dG7fccku0b98+CgsLo3HjxlFaWhrvvPNOzuuvvPLKKCkpiS5dukT79u3jggsuyLn1c+HChbF06dK46667Kp3fZ5xxRkT83/kNAHzHM54A2Gq6dOmSndXu+OOPj8MOOyxOOeWUeP/996OkpCQiIh5++OEYMmRIHH/88XH55ZdHkyZNom7dunH99dfnPIS8wvpm80rWeRh4Gta37c2taeDAgXH44YfHn//855g8eXLceOONccMNN8Tjjz8effr0ifLy8jjqqKNiyZIlceWVV8bee+8dxcXFMX/+/BgyZEilwGZL11dda9eujX333TduvvnmKn9fEczVr18/Xn755Zg6dWo8/fTT8dxzz8Wf/vSn6NmzZ0yePHmzZ2r7/uiYzVXVttPcb1XVPHDgwPjb3/4Wl19+eXTq1ClKSkpi7dq18eMf/7ha4dwPqTef/Wpd//znP6NXr16x9957x8033xytWrWKevXqxTPPPBO33HJLtfbFqFGj4te//nWceeaZ8d///d+xyy67RJ06deKSSy7JeX2HDh3i/fffj6eeeiqee+65mDBhQowZMyauvvrquOaaa7LLnnbaaTF48OAqt7XffvttmTcOANsIwRMAeVERJh1xxBFx++23x3/9139FRMT48eOjbdu28fjjj+eMpBg+fPhmbad169YR8d0onHW9//77lZadMmVKLF++PGfU06xZs3LWlabmzZvH+eefH+eff358/vnnccABB8R1110Xffr0ienTp8fs2bPjgQceiNNPPz37mhdeeCG1ej744IM44ogjsj9/9dVX8cknn8RPfvKT9b6mXbt28fbbb0evXr02+gDsOnXqRK9evaJXr15x8803x6hRo+Kqq66KqVOnxpFHHrlF3kPFcVv3eEd8d2wbN24cxcXFW2Rb67Ox/bCuL774Iv7yl7/ENddcE1dffXW2varzOF9at24dM2fOjCRJct7fhx9+uNHXlpaWRv369avVL5988slYtWpVTJo0KWcUV1UPMV/ffh4/fnwcccQRcc899+S0L126tNIotuLi4hg0aFAMGjQovv322zjhhBPiuuuui1/+8pdRWloaO+20U5SXl2/0/NzUYw4A2yq32gGQNz169IguXbrErbfeGitXroyI/xtp8f2RFW+++Wa8/vrrm7WN5s2bR6dOneKBBx7IuaXmhRdeiJkzZ+Ys+5Of/CTKy8vj9ttvz2m/5ZZbIpPJZGfzSkN5eXmlW4aaNGkSLVq0iFWrVkVE1fsmSZL43e9+l1pdd911V6xevTr78x133BFr1qzZ4L4YOHBgzJ8/P+6+++5Kv1uxYkX2trYlS5ZU+n3FrIUV73lL+P45sHTp0mz7u+++G5MnT95giLalFBcX52x7Y6o61hHfzdxWU/Tu3Tvmz58fkyZNyratXLmyyuO+rrp160bv3r1j4sSJ8a9//Svb/t5778Xzzz9fadmI3H2xbNmyuO+++yqtd337uW7dupX25WOPPRbz58/PaVu8eHHOz/Xq1YuysrJIkiRWr14ddevWjRNPPDEmTJgQ7777bqXtLFy4MKeWiNik4w4A2yIjngDIq8svvzwGDBgQ999/f5x33nlxzDHHxOOPPx4//elPo2/fvjF37ty48847o6ysLL766qvN2sb1118fffv2jcMOOyzOPPPMWLJkSdx2223RsWPHnHUee+yxccQRR8RVV10VH330Uey///4xefLkeOKJJ+KSSy6Jdu3abam3Xcny5ctjt912i/79+8f+++8fJSUlMWXKlJg2bVrcdNNNERGx9957R7t27eKyyy6L+fPnR4MGDWLChAlb5BlD6/Ptt99Gr169YuDAgfH+++/HmDFj4rDDDst5oPS6fvazn8Wjjz4a5513XkydOjW6du0a5eXlMWvWrHj00Ufj+eefjwMPPDBGjhwZL7/8cvTt2zdat24dn3/+eYwZMyZ22223OOyww7bo+7jxxhujT58+ccghh8RZZ50VK1asiNtuuy0aNmwYI0aM2KLbqkrnzp1jypQpcfPNN0eLFi1ijz32yD50vioNGjSIbt26xejRo2P16tXRsmXLmDx5csydOzf1Wqvr3HPPjdtvvz1OPvnkuPjii6N58+Yxbty4KCoqioiNj/i55ppr4rnnnovDDz88zj///FizZk22X77zzjvZ5Y4++uioV69eHHvssXHuuefGV199FXfffXc0adIkPvnkk5x1du7cOe6444649tprY88994wmTZpEz54945hjjomRI0fGGWecEYceemhMnz49xo0bF23bts15/dFHHx3NmjWLrl27RtOmTeO9996L22+/Pfr27ZsdBfmb3/wmpk6dGgcffHCcc845UVZWFkuWLIm33norpkyZkg1U27VrF40aNYo777wzdtpppyguLo6DDz64yud5AcA2bSvPogfAdqhiuvdp06ZV+l15eXnSrl27pF27dsmaNWuStWvXJqNGjUpat26dFBYWJv/5n/+ZPPXUU8ngwYOT1q1bZ183d+7cJCKSG2+8sdI6IyIZPnx4TtuECROSDh06JIWFhUlZWVny+OOPV1pnkiTJ8uXLk0svvTRp0aJFssMOOyTt27dPbrzxxmTt2rWVtnHBBRfktK2vpoop6x977LH17qNVq1Yll19+ebL//vsnO+20U1JcXJzsv//+yZgxY3KWmzlzZnLkkUcmJSUlSePGjZNzzjknefvttytN2z548OCkuLi40na6d+9e5XTxrVu3Tvr27Zv9ueKYvfTSS8nQoUOTnXfeOSkpKUlOPfXUZPHixZXWue4U9t9++21yww03JB07dkwKCwuTnXfeOencuXNyzTXXJMuWLUuSJEn+8pe/JMcdd1zSokWLpF69ekmLFi2Sk08+OZk9e/Z699OG3seGzokkSZIpU6YkXbt2TerXr580aNAgOfbYY5OZM2fmLDN8+PAkIpKFCxfmtG/q/lzXrFmzkm7duiX169dPIiIZPHjwBreXJEny8ccfJz/96U+TRo0aJQ0bNkwGDBiQLFiwoNL5XXGs5s6dm21b93h+v97vH6uKc3Pq1KkbfU9V9Zc5c+Ykffv2TerXr5+UlpYmw4YNSyZMmJBERPLGG29sdL+89NJLSefOnZN69eolbdu2Te68887sPvm+SZMmJfvtt19SVFSUtGnTJrnhhhuSe++9t9L7/vTTT5O+ffsmO+20UxIR2fe6cuXKZNiwYUnz5s2T+vXrJ127dk1ef/31Svtj7NixSbdu3ZJdd901KSwsTNq1a5dcfvnl2XO2wmeffZZccMEFSatWrZIddtghadasWdKrV6/krrvuylnuiSeeSMrKypKCgoJKfRQAtheZJMnDUyIBgBrt/vvvjzPOOCOmTZuWfSA8VMett94al156aXz88cfRsmXLfJcDAOSZZzwBALBZVqxYkfPzypUrY+zYsdG+fXuhEwAQEZ7xBADAZjrhhBNi9913j06dOsWyZcvi4YcfjlmzZsW4cePyXRoAUEMIngAA2Cy9e/eOP/zhDzFu3LgoLy+PsrKy+OMf/xiDBg3Kd2kAQA3hGU8AAAAApMIzngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheCplhgyZEhkMpn1/ps/f36+SwQ2wXXXXReZTCb22WeffJcCbMS0adPiwgsvjI4dO0ZxcXHsvvvuMXDgwJg9e3a+SwOqYcaMGTFgwIBo27Zt7LjjjtG4cePo1q1bPPnkk/kuDdgI/XfbUJDvAqiec889N4488sictiRJ4rzzzos2bdpEy5Yt81QZsKk+/vjjGDVqVBQXF+e7FKAabrjhhnjttddiwIABsd9++8Wnn34at99+exxwwAHxxhtvCJChhps3b14sX748Bg8eHC1atIhvvvkmJkyYEP369YuxY8fG0KFD810isB7677YhkyRJku8i2DyvvvpqHH744XHdddfFr371q3yXA1TTSSedFAsXLozy8vJYtGhRvPvuu/kuCdiAv/3tb3HggQdGvXr1sm0ffPBB7LvvvtG/f/94+OGH81gdsDnKy8ujc+fOsXLlypg1a1a+ywE2gf5b+7jVrhZ75JFHIpPJxCmnnJLvUoBqevnll2P8+PFx66235rsUoJoOPfTQnNApIqJ9+/bRsWPHeO+99/JUFfBD1K1bN1q1ahVLly7NdynAJtJ/ax+32tVSq1evjkcffTQOPfTQaNOmTb7LAaqhvLw8fvGLX8TZZ58d++67b77LAX6AJEnis88+i44dO+a7FKCavv7661ixYkUsW7YsJk2aFM8++2wMGjQo32UB1aD/1m6Cp1rq+eefj8WLF8epp56a71KAarrzzjtj3rx5MWXKlHyXAvxA48aNi/nz58fIkSPzXQpQTcOGDYuxY8dGRESdOnXihBNOiNtvvz3PVQHVof/WboKnWuqRRx6JHXbYIQYOHJjvUoBqWLx4cVx99dXx61//OkpLS/NdDvADzJo1Ky644II45JBDYvDgwfkuB6imSy65JPr37x8LFiyIRx99NMrLy+Pbb7/Nd1lANei/tZuHi9dCX331VTRt2jR69uxpGkmoJX7+85/HlClTYsaMGdlnxfTo0cPDxaGW+fTTT6Nr166xevXqeOONN6JFixb5LgnYTEcffXQsXbo03nzzzchkMvkuB9gE+m/t4uHitdDEiRPjm2++cZsd1BIffPBB3HXXXXHRRRfFggUL4qOPPoqPPvooVq5cGatXr46PPvoolixZku8ygY1YtmxZ9OnTJ5YuXRrPPfec0Alquf79+8e0adNi9uzZ+S4F2ET6b+0ieKqFxo0bFyUlJdGvX798lwJUw/z582Pt2rVx0UUXxR577JH99+abb8bs2bNjjz328JwYqOFWrlwZxx57bMyePTueeuqpKCsry3dJwA+0YsWKiPguVAZqF/23dvGMp1pm4cKFMWXKlDj55JNjxx13zHc5QDXss88+8ec//7lS+//7f/8vli9fHr/73e+iXbt2eagMqI7y8vIYNGhQvP766/HEE0/EIYccku+SgE3w+eefR5MmTXLaVq9eHQ8++GDUr19fkAw1mP67bRA81TJ/+tOfYs2aNW6zg1qkcePGcfzxx1dqv/XWWyMiqvwdUHMMGzYsJk2aFMcee2wsWbIkHn744Zzfn3baaXmqDKiOc889N7788svo1q1btGzZMj799NMYN25czJo1K2666aYoKSnJd4nAeui/2wYPF69lDjnkkJgzZ04sWLAg6tatm+9ygB/Aw8WhdujRo0e89NJL6/29r1JQs/3xj3+Me+65J6ZPnx6LFy+OnXbaKTp37hy/+MUvPLoCajj9d9sgeAIAAAAgFR4uDgAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqCqq7YCaTSbMOqPWSJMl3CRukD8OG1eQ+rP/ChtXk/huhD8PG1OQ+rP/ChlWn/xrxBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApKIg3wUAAGxMkiT5LiF1mUwm3yUAAGxxRjwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpKMh3AQAASZLkuwQgT7b3/p/JZPJdAkCqjHgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSUZDvAgAA2PCU8qZbp6bb0PnLhm1s3+n/VFc++qHzk+ow4gkAAACAVAieAAAAAEiF4AkAAACAVAieAAAAAEiF4AkAAACAVAieAAAAAEhFQb4LAAD4Ibb2VM6mjYeaIR/TuOej/29om6ayJ982t084d7cvRjwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpKMh3Adu7mjYls2ktYfuU1rXINYXqcq5A7ba99OHNfZ817Ts/26YNnZ817Rzc3Hq2l2vNtsaIJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBUF+S6gNqlpU1CmYUPv0dSVbMu2dv/OR3/aHq5hsKXko7/4nAWq4trAlvBDzqOa9B3yh9SiL+WPEU8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApELwBAAAAEAqBE8AAAAApKIg3wXUJEmS5LuEGi0f+yeTyWz1bbLt2h76+PbwHgEgX3zOsj3a3L/Jalp/SaMef69WjxFPAAAAAKRC8AQAAABAKgRPAAAAAKRC8AQAAABAKgRPAAAAAKRC8AQAAABAKgryXcDWVtOmdGTDTHnJpshH/95ezqft5X2yfXHNAKqyta8Nrgtsqzb33K5Nf7NvrFb9+ztGPAEAAACQCsETAAAAAKkQPAEAAACQCsETAAAAAKkQPAEAAACQCsETAAAAAKkoyHcBaahN0y9urpo2LeP2sM+pGZxrQE1X0z6jYVtVm74TuC5A9f2Q/lKbrgvbEyOeAAAAAEiF4AkAAACAVAieAAAAAEiF4AkAAACAVAieAAAAAEiF4AkAAACAVBTku4DNVZumSdwepk815SW1XW3qp/noM2lsszbtc2o2nyNQu+nDwJayoe+XrjX5Y8QTAAAAAKkQPAEAAACQCsETAAAAAKkQPAEAAACQCsETAAAAAKkQPAEAAACQioJ8F7CtMC04AGwffOYDQHqSJMl3CWxhRjwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpKMh3AbWJ6ZM3nykx2VY5t10b2Tq2dl9zXsO2a2P9O43rzYbW6XpDTef77vrpv9VjxBMAAAAAqRA8AQAAAJAKwRMAAAAAqRA8AQAAAJAKwRMAAAAAqRA8AQAAAJAKwRMAAAAAqSjIdwFbWyaTyXcJ26QkSbb6Nh1LtqR8nMM1if5Evm3vfRC2ZzXtM2hz69nc69jGXlfT9g/bHp/B+lnajHgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSUZDvAjaX6Q7TYSpN2Ha5bkIufSIdaX2XcLwA0rGx6+v28Dfiht6jz58fzognAAAAAFIheAIAAAAgFYInAAAAAFIheAIAAAAgFYInAAAAAFIheAIAAAAgFQX5LoCtr6ZNh2l6SjbFDzlftva5X5tqha0hH+e1z5jN5zoEQETN+izNx2fThrZZk/ZNTWbEEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkIqCfBdAOkyBDJXVpOlO9VFga3G9AWBbsbHv8z7zaiYjngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQIngAAAABIheAJAAAAgFQU5LsANk8+pomsSVPRA1XTT9ke1abz3jTPG1abjmVtlsZ5uL0cO/sOYNMZ8QQAAABAKgRPAAAAAKRC8AQAAABAKgRPAAAAAKRC8AQAAABAKgRPAAAAAKRC8AQAAABAKgryXQDAtipJknyXANsFfW3ry2Qy+S6BGmZj/bAmnTP5uGbUpPcPbBr994cz4gkAAACAVAieAAAAAEiF4AkAAACAVAieAAAAAEiF4AkAAACAVAieAAAAAEhFQb4LYP1M9QpURT8FthTXE7aWfHyvBbY9riW1kxFPAAAAAKRC8AQAAABAKgRPAAAAAKRC8AQAAABAKgRPAAAAAKRC8AQAAABAKgryXcD2Lh/TQZo6GbactPqwfsq2aEPntemRN8w1gS1pc88n/VRfBNgcRjwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpKMh3AbWJKWQBIB2mKIeab0P9dFv6nux6BPmVj+uJfp8uI54AAAAASIXgCQAAAIBUCJ4AAAAASIXgCQAAAIBUCJ4AAAAASIXgCQAAAIBUFOS7ADaP6R5h60ljSld9GIBtic81YFOk8f16Y1yn8seIJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBUF+S6gJsnHlI4AAACwPclkMvkuga3IiCcAAAAAUiF4AgAAACAVgicAAAAAUiF4AgAAACAVgicAAAAAUiF4AgAAACAVgicAAAAAUlGQ7wK2B5lMJt8lAAAAAGx1RjwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpEDwBAAAAkArBEwAAAACpKMh3ATVJJpPJdwlADeTaAAAAsHmMeAIAAAAgFYInAAAAAFIheAIAAAAgFYInAAAAAFIheAIAAAAgFYInAAAAAFKRSZIkyXcRAAAAAGx7jHgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBWCJwAAAABSIXgCAAAAIBX/Hx16UoMZ2Jn6AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1500x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Number of data points in the training dataset: {len(train_loader)}\")\n",
    "print(f\"Number of data points in the training dataset: {len(test_loader)}\")\n",
    "show_samples(train_loader, 5, \"Random samples from training dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "def idx_to_float(idx: np.ndarray, num_bins: int):\n",
    "    flt_zero_one = (idx + 0.5) / num_bins\n",
    "    return (2.0 * flt_zero_one) - 1.0\n",
    "\n",
    "def float_to_idx(flt: np.ndarray, num_bins: int):\n",
    "    flt_zero_one = (flt / 2.0) + 0.5\n",
    "    return torch.clamp(torch.floor(flt_zero_one * num_bins), min=0, max=num_bins - 1).long()\n",
    "\n",
    "def quantize(flt, num_bins: int):\n",
    "    return idx_to_float(float_to_idx(flt, num_bins), num_bins)\n",
    "\n",
    "\n",
    "def rgb_image_transform(x, num_bins=256):\n",
    "    return quantize((x * 2) - 1, num_bins).permute(1, 2, 0).contiguous()\n",
    "\n",
    "def get_image_grid_from_tensor(image_tensor, nrows=1):\n",
    "    return make_grid(image_tensor, nrow=nrows, normalize=True)\n",
    "\n",
    "class CIFAR10(torchvision.datasets.CIFAR10):\n",
    "    def __getitem__(self, idx):\n",
    "        return super().__getitem__(idx)[0]\n",
    "    \n",
    "def get_standard_transform(num_bins, train=True):\n",
    "    return transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.RandomHorizontalFlip() if train else nn.Identity(),\n",
    "                            transforms.Lambda(lambda x: rgb_image_transform(x, num_bins)),])\n",
    "\n",
    "def get_cifar10_datasets(num_bins:int = 16, root='./datasets/') -> tuple[Dataset, Dataset, Dataset]:\n",
    "    # create datasets, train and val are the same (apart from transform), test is official cifar10 test set\n",
    "    train_set = CIFAR10(root=root, train=True, download=True, transform=get_standard_transform(num_bins, train=True))\n",
    "    val_set = CIFAR10(root=root, train=True, download=True, transform=get_standard_transform(num_bins, train=False))\n",
    "    test_set = CIFAR10(root=root, train=False, download=True, transform=get_standard_transform(num_bins, train=False))\n",
    "    return train_set, val_set, test_set\n",
    "\n",
    "def get_cifar10_dataloaders(batch_size:int = 32, num_bins:int = 16, valid_size=0.01, seed=7) -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "\n",
    "    # get datasets\n",
    "    train_set, val_set, test_set = get_cifar10_datasets(num_bins)\n",
    "\n",
    "    # train and val are the same by default, split them up using SubsetRandomSampler\n",
    "    indices = list(range(len(train_set)))\n",
    "    split = int(valid_size*len(train_set))\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "    # create dataloaders, using samplers\n",
    "    train_loader = DataLoader(train_set, sampler=train_sampler, batch_size=batch_size, drop_last=True)\n",
    "    val_loader = DataLoader(val_set, sampler=valid_sampler, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MNIST(torchvision.datasets.MNIST):\n",
    "#     def __getitem__(self, idx):\n",
    "#         return super().__getitem__(idx)[0]\n",
    "\n",
    "# def bin_mnist_transform(x):\n",
    "#     return torch.bernoulli(x.permute(1, 2, 0).contiguous()).int()\n",
    "\n",
    "# transform = transforms.Compose([transforms.ToTensor(), transforms.Lambda(bin_mnist_transform)])\n",
    "# train_set = MNIST(root=DATAPATH, train=True, download=True, transform=transform)\n",
    "# val_set = MNIST(root=DATAPATH, train=True, download=True, transform=transform)\n",
    "# test_set = MNIST(root=DATAPATH, train=False, download=True, transform=transform)\n",
    "\n",
    "# batch_size = 512\n",
    "# train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)#, collate_fn=collate_dynamic_binarize)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)#, collate_fn=collate_dynamic_binarize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Number of data points in the training dataset: {len(train_loader)}\")\n",
    "# print(f\"Number of data points in the training dataset: {len(test_loader)}\")\n",
    "# show_samples(train_loader, 5, \"Random samples from training dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
